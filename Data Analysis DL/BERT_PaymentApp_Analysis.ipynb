{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the Libraries\n"
      ],
      "metadata": {
        "id": "rCys-06aoMW-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNXzSsljcyIU",
        "outputId": "db195465-4494-436c-b17b-80e61d8bff3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.1.72)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.4)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.3.1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: vaderSentiment in /usr/local/lib/python3.7/dist-packages (3.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from vaderSentiment) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->vaderSentiment) (2022.6.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some layers from the model checkpoint at bert-base-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the layers of TFBertModel were initialized from the model checkpoint at bert-base-cased.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#Installing and importing required libraries\n",
        "!pip install contractions\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "import tweepy\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')\n",
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "import contractions\n",
        "from bs4 import BeautifulSoup\n",
        "sid = SentimentIntensityAnalyzer()\n",
        "nltk.download('words')\n",
        "words = set(nltk.corpus.words.words())\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import string\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "#Adding sklearn library stop words to nltk library stop words\n",
        "from sklearn.feature_extraction import text\n",
        "sklearn_stop = text.ENGLISH_STOP_WORDS\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk_stop = stopwords.words('english')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "# Install Libraries\n",
        "!pip install -U textblob\n",
        "\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "# Import Libraries\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from textblob import TextBlob\n",
        "from wordcloud import WordCloud\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "import pandas as pd \n",
        "import numpy as np \n",
        "pd.options.display.max_colwidth=500\n",
        "\n",
        "import pickle \n",
        "import re \n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet') #(uncomment and run this line when running the code for first time)\n",
        "nltk.download('omw-1.4')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem.lancaster import LancasterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "\n",
        "stops = set(stopwords.words('english'))\n",
        "stemmer = SnowballStemmer('english')\n",
        "\n",
        "!pip install vaderSentiment\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "\n",
        "!pip install transformers\n",
        "import transformers\n",
        "from transformers import AutoTokenizer,TFBertModel\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
        "bert = TFBertModel.from_pretrained('bert-base-cased')\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.initializers import TruncatedNormal\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import CategoricalAccuracy\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "#mount google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the data"
      ],
      "metadata": {
        "id": "kx3tqVosoWXf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dSh_661Lc3Bv",
        "outputId": "c8c8c005-fad2-4aaf-9536-eb4ca1311f5a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  application                       date  \\\n",
              "0   GooglePay  2022-08-28 19:44:29+00:00   \n",
              "1   GooglePay  2022-08-28 19:36:02+00:00   \n",
              "2   GooglePay  2022-08-28 19:20:39+00:00   \n",
              "3   GooglePay  2022-08-28 18:31:49+00:00   \n",
              "4   GooglePay  2022-08-28 18:31:30+00:00   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                            content  \\\n",
              "0  I have recharged for my mother number in @airtelindia thanks app and paid amount using UPI app option @GooglePay. Amount debited but not reflected. Reached support for both but saying it's not our mistake reach other. It's been 2mnts+ but no refund. @airtelindia closing my ticket https://t.co/qVwXkQMEVs   \n",
              "1                                                                                                                                                                                                                                                          @YusufzaiZahid @PhonePe @GooglePay what was the matter??   \n",
              "2                                                                 @zushah_ Hi there. Thanks for your interest! You can learn more about Google Wallet at The Keyword blog: https://t.co/BSQPLxGXSP. Stay tuned for more information about the launch. We are working hard to bring Google Wallet to more countries!   \n",
              "3                                                                                                                                                                                    Google Wallet Not Available ðŸ˜­ In Pakistan ðŸ‡µðŸ‡° @Google @GooglePay @GooglePayDevs @GooglePlay @googledevs @GoogleTrends @GoogleAI   \n",
              "4                           @GooglePay offered me a coupon for a certain amount off, of @skullcandy earbuds. Very happily, I jumped on to buy them, entered the code and it went through- never once did it tell me that the code has expired or whatever, but my amazon pay was deducted for the price. #Returned.   \n",
              "\n",
              "         userid      username             displayname followersCount  \\\n",
              "0    1.5398e+18  venkata_loya  Venkata Sai Kumar Loya              0   \n",
              "1    48290561.0   ArifKIndian           | Arif Khan |           7006   \n",
              "2   309827046.0     GooglePay              Google Pay         134379   \n",
              "3   1.36178e+18       zushah_              Ø²ÙˆÙ‡Ø§ÙŠØ¨ Ø´Ø§Ù‡              3   \n",
              "4  2571833710.0    ChauIsAuth         Ishan Chauhan â™¿            388   \n",
              "\n",
              "  friendsCount             location replycount likecount retweetcount  \\\n",
              "0            5                   in          1         0            0   \n",
              "1          920                India          0         0            0   \n",
              "2          136                   in          0         0            0   \n",
              "3          108  Islamabad, Pakistan          1         0            0   \n",
              "4         2677                   in          2         0            0   \n",
              "\n",
              "  language               source  \\\n",
              "0       en  Twitter for Android   \n",
              "1       hi   Twitter for iPhone   \n",
              "2       en     Verint Messaging   \n",
              "3       en  Twitter for Android   \n",
              "4       en      Twitter Web App   \n",
              "\n",
              "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        mentionedusers  \\\n",
              "0  [User(username='airtelindia', id=176355348, displayname='airtel India', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None), User(username='GooglePay', id=309827046, displayname='Google Pay', description=None, rawDescripti...   \n",
              "1  [User(username='YusufzaiZahid', id=1435098404, displayname='Zahid Yusufzai ðŸ‡®ðŸ‡³ Ø²Ø§Ù‡Ø¯ Ø®Ø§Ù†', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None), User(username='PhonePe', id=4910896514, displayname='PhonePe', description=None,...   \n",
              "2                                                                                                   [User(username='zushah_', id=1361784480600633345, displayname='Ø²ÙˆÙ‡Ø§ÙŠØ¨ Ø´Ø§Ù‡', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None)]   \n",
              "3  [User(username='Google', id=20536157, displayname='Google', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None), User(username='GooglePay', id=309827046, displayname='Google Pay', description=None, rawDescription=None, des...   \n",
              "4  [User(username='GooglePay', id=309827046, displayname='Google Pay', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None), User(username='skullcandy', id=29009790, displayname='Skullcandy', description=None, rawDescription=N...   \n",
              "\n",
              "  retweetedtweet      hashtags  \n",
              "0            nan           nan  \n",
              "1            nan           nan  \n",
              "2            nan           nan  \n",
              "3            nan           nan  \n",
              "4            nan  ['Returned']  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7c9a5f7-dd50-4b8c-948c-dc434f9ea40d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>application</th>\n",
              "      <th>date</th>\n",
              "      <th>content</th>\n",
              "      <th>userid</th>\n",
              "      <th>username</th>\n",
              "      <th>displayname</th>\n",
              "      <th>followersCount</th>\n",
              "      <th>friendsCount</th>\n",
              "      <th>location</th>\n",
              "      <th>replycount</th>\n",
              "      <th>likecount</th>\n",
              "      <th>retweetcount</th>\n",
              "      <th>language</th>\n",
              "      <th>source</th>\n",
              "      <th>mentionedusers</th>\n",
              "      <th>retweetedtweet</th>\n",
              "      <th>hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>GooglePay</td>\n",
              "      <td>2022-08-28 19:44:29+00:00</td>\n",
              "      <td>I have recharged for my mother number in @airtelindia thanks app and paid amount using UPI app option @GooglePay. Amount debited but not reflected. Reached support for both but saying it's not our mistake reach other. It's been 2mnts+ but no refund. @airtelindia closing my ticket https://t.co/qVwXkQMEVs</td>\n",
              "      <td>1.5398e+18</td>\n",
              "      <td>venkata_loya</td>\n",
              "      <td>Venkata Sai Kumar Loya</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>in</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>[User(username='airtelindia', id=176355348, displayname='airtel India', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None), User(username='GooglePay', id=309827046, displayname='Google Pay', description=None, rawDescripti...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GooglePay</td>\n",
              "      <td>2022-08-28 19:36:02+00:00</td>\n",
              "      <td>@YusufzaiZahid @PhonePe @GooglePay what was the matter??</td>\n",
              "      <td>48290561.0</td>\n",
              "      <td>ArifKIndian</td>\n",
              "      <td>| Arif Khan |</td>\n",
              "      <td>7006</td>\n",
              "      <td>920</td>\n",
              "      <td>India</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hi</td>\n",
              "      <td>Twitter for iPhone</td>\n",
              "      <td>[User(username='YusufzaiZahid', id=1435098404, displayname='Zahid Yusufzai ðŸ‡®ðŸ‡³ Ø²Ø§Ù‡Ø¯ Ø®Ø§Ù†', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None), User(username='PhonePe', id=4910896514, displayname='PhonePe', description=None,...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>GooglePay</td>\n",
              "      <td>2022-08-28 19:20:39+00:00</td>\n",
              "      <td>@zushah_ Hi there. Thanks for your interest! You can learn more about Google Wallet at The Keyword blog: https://t.co/BSQPLxGXSP. Stay tuned for more information about the launch. We are working hard to bring Google Wallet to more countries!</td>\n",
              "      <td>309827046.0</td>\n",
              "      <td>GooglePay</td>\n",
              "      <td>Google Pay</td>\n",
              "      <td>134379</td>\n",
              "      <td>136</td>\n",
              "      <td>in</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "      <td>Verint Messaging</td>\n",
              "      <td>[User(username='zushah_', id=1361784480600633345, displayname='Ø²ÙˆÙ‡Ø§ÙŠØ¨ Ø´Ø§Ù‡', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None)]</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>GooglePay</td>\n",
              "      <td>2022-08-28 18:31:49+00:00</td>\n",
              "      <td>Google Wallet Not Available ðŸ˜­ In Pakistan ðŸ‡µðŸ‡° @Google @GooglePay @GooglePayDevs @GooglePlay @googledevs @GoogleTrends @GoogleAI</td>\n",
              "      <td>1.36178e+18</td>\n",
              "      <td>zushah_</td>\n",
              "      <td>Ø²ÙˆÙ‡Ø§ÙŠØ¨ Ø´Ø§Ù‡</td>\n",
              "      <td>3</td>\n",
              "      <td>108</td>\n",
              "      <td>Islamabad, Pakistan</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "      <td>Twitter for Android</td>\n",
              "      <td>[User(username='Google', id=20536157, displayname='Google', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None), User(username='GooglePay', id=309827046, displayname='Google Pay', description=None, rawDescription=None, des...</td>\n",
              "      <td>nan</td>\n",
              "      <td>nan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GooglePay</td>\n",
              "      <td>2022-08-28 18:31:30+00:00</td>\n",
              "      <td>@GooglePay offered me a coupon for a certain amount off, of @skullcandy earbuds. Very happily, I jumped on to buy them, entered the code and it went through- never once did it tell me that the code has expired or whatever, but my amazon pay was deducted for the price. #Returned.</td>\n",
              "      <td>2571833710.0</td>\n",
              "      <td>ChauIsAuth</td>\n",
              "      <td>Ishan Chauhan â™¿</td>\n",
              "      <td>388</td>\n",
              "      <td>2677</td>\n",
              "      <td>in</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>en</td>\n",
              "      <td>Twitter Web App</td>\n",
              "      <td>[User(username='GooglePay', id=309827046, displayname='Google Pay', description=None, rawDescription=None, descriptionUrls=None, verified=None, created=None, followersCount=None, friendsCount=None, statusesCount=None, favouritesCount=None, listedCount=None, mediaCount=None, location=None, protected=None, linkUrl=None, linkTcourl=None, profileImageUrl=None, profileBannerUrl=None, label=None), User(username='skullcandy', id=29009790, displayname='Skullcandy', description=None, rawDescription=N...</td>\n",
              "      <td>nan</td>\n",
              "      <td>['Returned']</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7c9a5f7-dd50-4b8c-948c-dc434f9ea40d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7c9a5f7-dd50-4b8c-948c-dc434f9ea40d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7c9a5f7-dd50-4b8c-948c-dc434f9ea40d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#Reading the for payment apps\n",
        "\n",
        "cust_data = pd.read_csv('/content/drive/MyDrive/thesis folder/ewallet_tweets.csv',encoding = 'utf-8-sig')\n",
        "cust_data = cust_data.astype(str)\n",
        "cust_data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning\n"
      ],
      "metadata": {
        "id": "fBll1zt8oaU0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "WY4bXDxdeMVZ"
      },
      "outputs": [],
      "source": [
        "cust_data['content'] = cust_data['content'].str.lower()\n",
        "cust_data.head()\n",
        "\n",
        "import re\n",
        "\n",
        "def remove_URL(text):\n",
        "    \"\"\"Remove URLs from a text string\"\"\"\n",
        "    return re.sub(r\"http\\S+\", \"\", text)\n",
        "\n",
        "#contraction word conversion\n",
        "\n",
        "cust_data['cleaned_text'] = cust_data['content'].apply(lambda tx: ' '.join([contractions.fix(word) for word in tx.split()]))\n",
        "\n",
        "# cust_data.head()\n",
        "\n",
        "\n",
        "def clean_text(review):\n",
        "    cleaning_text = remove_URL(review)\n",
        "    # cleaning_text = BeautifulSoup(review, 'html.parser').get_text()\n",
        "    cleaning_text = re.sub('[^a-zA-Z]', ' ', cleaning_text)\n",
        "    cleaning_text = cleaning_text.lower().split()\n",
        "    punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "    cleaning_text = [w for w in cleaning_text if not w in punctuations] \n",
        "    cleaning_text = [w for w in cleaning_text if not w in stops]\n",
        "    cleaning_text = [lemmatizer.lemmatize(w) for w in cleaning_text]\n",
        "    return( ' '.join(cleaning_text))\n",
        "\n",
        "cust_data['clean_text'] = cust_data['content'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing"
      ],
      "metadata": {
        "id": "MNwnkQhGpq-5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "e0N6rGWudHgn"
      },
      "outputs": [],
      "source": [
        "# defining function for Vader Sentiment Analysis\n",
        "\n",
        "\n",
        "def sentiment_Vader(tweet):\n",
        "    over_all_polarity = sid.polarity_scores(tweet)\n",
        "    if over_all_polarity['compound'] > 0.00:\n",
        "        return \"positive\"\n",
        "    elif over_all_polarity['compound'] < 0:\n",
        "        return \"negative\"\n",
        "    else:\n",
        "        return \"neutral\"\n",
        "\n",
        "\n",
        "sid = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wyvRo25Edbeg"
      },
      "outputs": [],
      "source": [
        "#Finding sentiments using Vader label\n",
        "cust_data['sentiment_label'] = cust_data['clean_text'].apply(lambda x: sentiment_Vader(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "T6o4HFSteKa7"
      },
      "outputs": [],
      "source": [
        "#Categorical encoding\n",
        "encoded_dict = {'neutral':0,'positive':1, 'negative':-1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EQeX3XnVebKh"
      },
      "outputs": [],
      "source": [
        "#Splitting the dataset into train-test\n",
        "X_train, X_test, y_train, y_test = train_test_split(cust_data['clean_text'], cust_data['sentiment_label'], stratify = cust_data['sentiment_label'], test_size = 0.2);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vaHPStGFgjTZ"
      },
      "outputs": [],
      "source": [
        "#Creating dataset for training and testing \n",
        "df_train = pd.DataFrame({'tweet':X_train, 'sentiment_label':y_train.values})\n",
        "df_test = pd.DataFrame({'tweet':X_test, 'sentiment_label':y_test.values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SkdDij2ietGU"
      },
      "outputs": [],
      "source": [
        "#Applying categorical encoding to sentiments\n",
        "df_train['Sentiment'] = df_train.sentiment_label.map(encoded_dict)\n",
        "df_test['Sentiment'] = df_test.sentiment_label.map(encoded_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "U4pHjyjQhUA7"
      },
      "outputs": [],
      "source": [
        "y_train = to_categorical(df_train.Sentiment,num_classes=3)\n",
        "y_test = to_categorical(df_test.Sentiment,num_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model training"
      ],
      "metadata": {
        "id": "G_LVdAHIpvTJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JM_sHpXBhoOV"
      },
      "outputs": [],
      "source": [
        "# Tokenize the input using from bert-base-cased\n",
        "x_train = tokenizer(\n",
        "    text=df_train.tweet.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=70,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "x_test = tokenizer(\n",
        "    text=df_test.tweet.tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=70,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "\n",
        "input_ids = x_train['input_ids']\n",
        "attention_mask = x_train['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "FC6Rpdk-h0Em"
      },
      "outputs": [],
      "source": [
        "#Defining model\n",
        "max_len = 70\n",
        "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
        "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
        "embeddings = bert(input_ids,attention_mask = input_mask)[0] \n",
        "out = tf.keras.layers.GlobalMaxPool1D()(embeddings)\n",
        "out = Dense(128, activation='relu')(out)\n",
        "out = tf.keras.layers.Dropout(0.1)(out)\n",
        "out = Dense(32,activation = 'relu')(out)\n",
        "y = Dense(3,activation = 'sigmoid')(out)\n",
        "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
        "model.layers[2].trainable = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "29Dr8djShf_R"
      },
      "outputs": [],
      "source": [
        "optimizer = Adam(\n",
        "    learning_rate=5e-05, # this learning rate is for bert model , taken from huggingface website \n",
        "    epsilon=1e-08,\n",
        "    decay=0.01,\n",
        "    clipnorm=1.0)\n",
        "# Set loss and metrics\n",
        "loss =CategoricalCrossentropy(from_logits = True)\n",
        "metric = CategoricalAccuracy('balanced_accuracy'),\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = loss, \n",
        "    metrics = metric)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVxx0SAaiyWu",
        "outputId": "251ef728-d629-42b0-f837-5014213ae6a5"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "175/175 [==============================] - 13364s 76s/step - loss: 0.5186 - balanced_accuracy: 0.7855 - val_loss: 0.3053 - val_balanced_accuracy: 0.8964\n",
            "Epoch 2/2\n",
            "175/175 [==============================] - 13329s 76s/step - loss: 0.2368 - balanced_accuracy: 0.9188 - val_loss: 0.2438 - val_balanced_accuracy: 0.9148\n"
          ]
        }
      ],
      "source": [
        "#model training\n",
        "train_history = model.fit(\n",
        "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
        "    y = y_train,\n",
        "    validation_data = (\n",
        "    {'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']}, y_test\n",
        "    ),\n",
        "  epochs=2,\n",
        "    batch_size=100\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_raw = model.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})\n",
        "predicted_raw[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMlaYJE_LzCV",
        "outputId": "7e755588-cff3-437a-8732-7917b39836d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9680141 , 0.333566  , 0.17906198], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#predicting for test data\n",
        "y_predicted = np.argmax(predicted_raw, axis = 1)\n",
        "y_true = df_test.Sentiment"
      ],
      "metadata": {
        "id": "lEQ9FbqXpNT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bleir7OWVMU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eee3fb25-cbec-48a7-b665-217c0ab23467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.00      0.00      0.00      1053\n",
            "           0       0.96      0.90      0.93      1370\n",
            "           1       0.91      0.93      0.92      1932\n",
            "           2       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.70      4355\n",
            "   macro avg       0.47      0.46      0.46      4355\n",
            "weighted avg       0.71      0.70      0.70      4355\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Evalation for bert based model\n",
        "print(classification_report(y_true, y_predicted))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [],
      "name": "BERT_PaymentApp_Analysis.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}